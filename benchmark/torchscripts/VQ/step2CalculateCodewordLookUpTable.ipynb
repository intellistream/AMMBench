{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have have run the executable of step1SaveMtxToPt.cpp, in you MtxPt/ under build/ dir, you should get\n",
    "\n",
    "```\n",
    "/home/miter/projects/AMMBench/build/benchmark/torchscripts/VQ/MtxPt\n",
    "├── MNIST_A.pt\n",
    "├── MNIST_B.pt\n",
    "├── SIFT_A.pt\n",
    "└── SIFT_B.pt\n",
    "```\n",
    "\n",
    "This jupuyer is to generate the codeword & lookup table for each pair of matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCodewordAndLookUpTable(A, B, m):\n",
    "    \n",
    "    # Sample matrix sizes and PQ parameters\n",
    "    A_rows, A_cols = A.shape\n",
    "    lA = A_rows // m // 10  # Number of centroids for each subspace\n",
    "    CA = A_cols // m  # Dimension of each subspace\n",
    "\n",
    "    # Sample matrix sizes and PQ parameters\n",
    "    B_rows, B_cols = B.shape\n",
    "    lB = B_cols // m // 10  # Number of centroids for each subspace\n",
    "    CB = B_rows // m  # Dimension of each subspace\n",
    "\n",
    "    # Initialize lists to store subspaces and centroids\n",
    "    subspaces_A = []\n",
    "    codewords_A = []\n",
    "\n",
    "    # Create subspaces and centroids\n",
    "    for i in range(m):\n",
    "        subspace_A = A[:, i * CA : (i + 1) * CA]  # 500*20\n",
    "        subspaces_A.append(subspace_A)\n",
    "\n",
    "        # Apply KMeans on the row vectors within the subspace\n",
    "        kmeans = KMeans(n_clusters=lA, n_init=10)\n",
    "        kmeans.fit(subspace_A)  # 500*20\n",
    "        subspace_centroids_A = torch.tensor(kmeans.cluster_centers_) # 10*20\n",
    "        codewords_A.append(subspace_centroids_A)\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    subspaces_A = torch.stack(subspaces_A, dim=0)\n",
    "    codewords_A = torch.stack(codewords_A, dim=0) # 5*10*20\n",
    "\n",
    "    print(\"Subspaces A shape:\", subspaces_A.shape) # torch.Size([5, 500, 20])\n",
    "    print(\"Codewords A shape:\", codewords_A.shape) # torch.Size([5, 10, 20])\n",
    "\n",
    "\n",
    "    # Initialize lists to store subspaces and centroids\n",
    "    subspaces_B = []\n",
    "    codewords_B = []\n",
    "\n",
    "    # Create subspaces and centroids\n",
    "    for k in range(m):\n",
    "        subspace_B = B[k * CB : (k + 1) * CB, :]  # Extract the subspace along x-axis\n",
    "        subspaces_B.append(subspace_B)\n",
    "\n",
    "        # Apply KMeans on the column vectors within the subspace\n",
    "        kmeans = KMeans(n_clusters=lB, n_init=10)\n",
    "        kmeans.fit(subspace_B.T)  # Transpose to cluster along columns (column vectors)\n",
    "        subspace_centroids_B = torch.tensor(kmeans.cluster_centers_)\n",
    "        codewords_B.append(subspace_centroids_B)\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    subspaces_B = torch.stack(subspaces_B, dim=0)\n",
    "    codewords_B = torch.stack(codewords_B, dim=0)\n",
    "\n",
    "    print(\"Subspaces B shape:\", subspaces_B.shape)  # torch.Size([5, 20, 300])\n",
    "    print(\"Codewords B shape:\", codewords_B.shape)  # torch.Size([5, 6, 20])\n",
    "\n",
    "    # Sample precomputed codewords for A and B (You should replace these with your actual codewords)\n",
    "    lookup_table = torch.zeros((m,lA,lB))\n",
    "    for i in range(m):\n",
    "        for j in range(lA):\n",
    "            for k in range(lB):\n",
    "                lookup_table[i][j][k] = torch.matmul(codewords_A[i][j], codewords_B[i][k]) # for each subspace, get catersian product of A,B codeword\n",
    "\n",
    "    print(\"lookup_table.shape: \", lookup_table.shape)\n",
    "\n",
    "    return lA, lB, codewords_A, codewords_B, lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to save codeword and lookup_table to pt\n",
    "class TensorContainer(nn.Module):\n",
    "    def __init__(self, tensor_dict):\n",
    "        super().__init__()\n",
    "        for key,value in tensor_dict.items():\n",
    "            setattr(self, key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(C, D, codewords_A, codewords_B, lookup_table):\n",
    "    m = codewords_A.shape[0]\n",
    "\n",
    "    # Sample matrix sizes and PQ parameters\n",
    "    C_rows, C_cols = C.shape\n",
    "    CC = codewords_A.shape[2]  # Dimension of each subspace for matrix C\n",
    "\n",
    "    D_rows, D_cols = D.shape\n",
    "    CD = codewords_B.shape[2]  # Dimension of each subspace for matrix D\n",
    "\n",
    "    # Initialize lists to store quantized indices\n",
    "    C_quantized = []\n",
    "    D_quantized = []\n",
    "\n",
    "    # Find the nearest codeword indices for matrix C\n",
    "    for i in range(m):\n",
    "        codewords_c = codewords_A[i] # torch.Size([10, 20])\n",
    "        C_subspace = C[:, i * CC : (i + 1) * CC] # torch.Size([500, 20])\n",
    "        distances = torch.norm(codewords_c.unsqueeze(0) - C_subspace.unsqueeze(1), dim=2, p=2) # torch.Size([500, 10]) = torch.Size([1, 10, 20]) - torch.Size([500, 1, 20])\n",
    "        closest_codeword_indices = torch.argmin(distances, dim=1) # torch.Size([500])\n",
    "        C_quantized.append(closest_codeword_indices)\n",
    "    C_quantized = torch.stack(C_quantized, dim=1) # torch.Size([500, 5])\n",
    "    # print(\"C quantized shape:\", C_quantized.shape)  # Shape of the quantized indices for C\n",
    "\n",
    "    # Find the nearest codeword indices for matrix D\n",
    "    for k in range(m):\n",
    "        codewords_d = codewords_B[k]\n",
    "        D_subspace = D[k * CD : (k + 1) * CD, :] # torch.Size([20, 300])\n",
    "        distances = torch.norm(codewords_d.unsqueeze(0) - torch.swapaxes(D_subspace.unsqueeze(1), 0, 2), dim=2, p=2) # torch.Size([300, 6]) = torch.Size([1, 6, 20]) - torch.Size([300, 1, 20])\n",
    "        closest_codeword_indices = torch.argmin(distances, dim=1) # torch.Size([300])\n",
    "        D_quantized.append(closest_codeword_indices.T)\n",
    "    D_quantized = torch.stack(D_quantized, dim=0) # torch.Size([5, 300])\n",
    "    # print(\"D quantized shape:\", D_quantized.shape)  # Shape of the quantized indices for D\n",
    "\n",
    "    # Define the batch size for batch processing\n",
    "    batch_size_C = C_rows\n",
    "    batch_size_D = D_cols\n",
    "\n",
    "    # Initialize the matrix products\n",
    "    matrix_products = torch.zeros((C_rows, D_cols))\n",
    "\n",
    "    # Perform matrix multiplication using batch processing\n",
    "    for i in range(0, C_rows, batch_size_C):\n",
    "        for j in range(0, D_cols, batch_size_D):\n",
    "            batch_result = torch.zeros((batch_size_C, batch_size_D))\n",
    "            \n",
    "            for k in range(m):\n",
    "                # Gather quantized indices for the current batch\n",
    "                C_indices = C_quantized[i:i+batch_size_C, k]\n",
    "                D_indices = D_quantized[k, j:j+batch_size_D]\n",
    "                \n",
    "                # Gather relevant entries from the lookup table\n",
    "                batch_lookup = lookup_table[k, C_indices, :][:, D_indices]\n",
    "                \n",
    "                # Accumulate the batch result\n",
    "                batch_result += batch_lookup\n",
    "            \n",
    "            # Assign the batch result to the corresponding position in the matrix products\n",
    "            matrix_products[i:i+batch_size_C, j:j+batch_size_D] = batch_result\n",
    "\n",
    "    E = torch.matmul(C, D)\n",
    "    return torch.norm(matrix_products-E)/torch.norm(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pls not run below, keep the output for future reference\n",
    "\n",
    "# datasetDir = '/home/miter/projects/AMMBench/build/benchmark/torchscripts/VQ/MtxPt'\n",
    "# saveDir = '/home/miter/projects/AMMBench/build/benchmark/torchscripts/VQ/CodewordLookUpTable'\n",
    "\n",
    "# for datasetName in [\"AST\",\"BUS\",\"DWAVE\",\"ECO\",\"QCD\",\"RDB\",\"UTM\",\"ZENIOS\"]:\n",
    "#     for m in [1, 10]: # Number of subspaces\n",
    "\n",
    "#         # load\n",
    "#         A = torch.load(f'{datasetDir}/{datasetName}_A.pt')\n",
    "#         B = torch.load(f'{datasetDir}/{datasetName}_B.pt')\n",
    "\n",
    "#         # calculate codeword and lookup_table\n",
    "#         lA, lB, codewords_A, codewords_B, lookup_table = getCodewordAndLookUpTable(A, B, m)\n",
    "\n",
    "#         # calculate error\n",
    "#         C=A # actually C,D are testing matrices, and usually different from training matrices A,B. but its ok to make them the same also, cuz we more focus on latency\n",
    "#         D=B\n",
    "#         relativeFroError = quantize(C, D, codewords_A, codewords_B, lookup_table)\n",
    "\n",
    "#         # save codeword and lookup_table\n",
    "#         tensor_dict = {\n",
    "#             # 'A': A,\n",
    "#             # 'B': B,\n",
    "#             'codewordsA': codewords_A,\n",
    "#             'codewordsB': codewords_B,\n",
    "#             'lookUpTable': lookup_table,\n",
    "#             'datasetName': datasetName,\n",
    "#             'm': m,\n",
    "#             'lA': lA,\n",
    "#             'lB': lB,\n",
    "#             'relativeFroError': relativeFroError\n",
    "#         }\n",
    "#         tensors = TensorContainer(tensor_dict)\n",
    "#         tensors = torch.jit.script(tensors)\n",
    "#         tensors.save(f'{saveDir}/{datasetName}_m{m}_lA{lA}_lB{lB}.pth')\n",
    "#         print(datasetName, m, lA, lB, relativeFroError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "datasetDir = '/home/shuhao/Downloads/AMMBench/build/benchmark/torchscripts/VQ/MtxPt'\n",
    "saveDir = '/home/shuhao/Downloads/AMMBench/build/benchmark/torchscripts/VQ/CodewordLookUpTable'\n",
    "\n",
    "for datasetName in [\"GIST1M\"]:\n",
    "    for m in [1, 10]: # Number of subspaces\n",
    "\n",
    "        # load\n",
    "        A = torch.load(f'{datasetDir}/{datasetName}_A.pt')\n",
    "        B = torch.load(f'{datasetDir}/{datasetName}_B.pt')\n",
    "\n",
    "        # calculate codeword and lookup_table\n",
    "        lA, lB, codewords_A, codewords_B, lookup_table = getCodewordAndLookUpTable(A, B, m)\n",
    "\n",
    "        # calculate error\n",
    "        C=A # actually C,D are testing matrices, and usually different from training matrices A,B. but its ok to make them the same also, cuz we more focus on latency\n",
    "        D=B\n",
    "        relativeFroError = \"notCalculated\" #quantize(C, D, codewords_A, codewords_B, lookup_table)\n",
    "\n",
    "        # save codeword and lookup_table\n",
    "        tensor_dict = {\n",
    "            # 'A': A,\n",
    "            # 'B': B,\n",
    "            'codewordsA': codewords_A,\n",
    "            'codewordsB': codewords_B,\n",
    "            'lookUpTable': lookup_table,\n",
    "            'datasetName': datasetName,\n",
    "            'm': m,\n",
    "            'lA': lA,\n",
    "            'lB': lB,\n",
    "            'relativeFroError': relativeFroError\n",
    "        }\n",
    "        tensors = TensorContainer(tensor_dict)\n",
    "        tensors = torch.jit.script(tensors)\n",
    "        tensors.save(f'{saveDir}/{datasetName}_m{m}_lA{lA}_lB{lB}.pth')\n",
    "        print(datasetName, m, lA, lB, relativeFroError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subspaces A shape: torch.Size([1, 392, 60000])\n",
      "Codewords A shape: torch.Size([1, 39, 60000])\n",
      "Subspaces B shape: torch.Size([1, 60000, 392])\n",
      "Codewords B shape: torch.Size([1, 39, 60000])\n",
      "lookup_table.shape:  torch.Size([1, 39, 39])\n",
      "AA MNIST 1 39 39 tensor(0.6131)\n",
      "Subspaces A shape: torch.Size([1, 392, 60000])\n",
      "Codewords A shape: torch.Size([1, 39, 60000])\n",
      "Subspaces B shape: torch.Size([1, 60000, 392])\n",
      "Codewords B shape: torch.Size([1, 39, 60000])\n",
      "lookup_table.shape:  torch.Size([1, 39, 39])\n",
      "AB MNIST 1 39 39 tensor(0.5322)\n",
      "Subspaces A shape: torch.Size([1, 392, 60000])\n",
      "Codewords A shape: torch.Size([1, 39, 60000])\n",
      "Subspaces B shape: torch.Size([1, 60000, 392])\n",
      "Codewords B shape: torch.Size([1, 39, 60000])\n",
      "lookup_table.shape:  torch.Size([1, 39, 39])\n",
      "BB MNIST 1 39 39 tensor(0.6203)\n",
      "Subspaces A shape: torch.Size([10, 392, 6000])\n",
      "Codewords A shape: torch.Size([10, 3, 6000])\n",
      "Subspaces B shape: torch.Size([10, 6000, 392])\n",
      "Codewords B shape: torch.Size([10, 3, 6000])\n",
      "lookup_table.shape:  torch.Size([10, 3, 3])\n",
      "AA MNIST 10 3 3 tensor(0.9204)\n",
      "Subspaces A shape: torch.Size([10, 392, 6000])\n",
      "Codewords A shape: torch.Size([10, 3, 6000])\n",
      "Subspaces B shape: torch.Size([10, 6000, 392])\n",
      "Codewords B shape: torch.Size([10, 3, 6000])\n",
      "lookup_table.shape:  torch.Size([10, 3, 3])\n",
      "AB MNIST 10 3 3 tensor(0.8725)\n",
      "Subspaces A shape: torch.Size([10, 392, 6000])\n",
      "Codewords A shape: torch.Size([10, 3, 6000])\n",
      "Subspaces B shape: torch.Size([10, 6000, 392])\n",
      "Codewords B shape: torch.Size([10, 3, 6000])\n",
      "lookup_table.shape:  torch.Size([10, 3, 3])\n",
      "BB MNIST 10 3 3 tensor(0.8756)\n"
     ]
    }
   ],
   "source": [
    "# def saveCodewordsAndLookUpTable(A, B, m, prefix):\n",
    "#     # calculate codeword and lookup_table\n",
    "#     lA, lB, codewords_A, codewords_B, lookup_table = getCodewordAndLookUpTable(A, B, m)\n",
    "#     # calculate error\n",
    "#     C=A\n",
    "#     D=B\n",
    "#     relativeFroError = quantize(C, D, codewords_A, codewords_B, lookup_table)\n",
    "#     # save codeword and lookup_table\n",
    "#     tensor_dict = {\n",
    "#         # 'A': A,\n",
    "#         # 'B': B,\n",
    "#         'codewordsA': codewords_A,\n",
    "#         'codewordsB': codewords_B,\n",
    "#         'lookUpTable': lookup_table,\n",
    "#         'datasetName': datasetName,\n",
    "#         'm': m,\n",
    "#         'lA': lA,\n",
    "#         'lB': lB,\n",
    "#         'relativeFroError': relativeFroError\n",
    "#     }\n",
    "#     tensors = TensorContainer(tensor_dict)\n",
    "#     tensors = torch.jit.script(tensors)\n",
    "#     tensors.save(f'{saveDir}/{datasetName}_{prefix}_m{m}_lA{lA}_lB{lB}.pth')\n",
    "#     print(prefix, datasetName, m, lA, lB, relativeFroError)\n",
    "    \n",
    "# datasetDir = '/home/miter/projects/AMMBench/build/benchmark/torchscripts/VQ/MtxPt'\n",
    "# saveDir = '/home/miter/projects/AMMBench/build/benchmark/torchscripts/VQ/CodewordLookUpTable'\n",
    "\n",
    "# for datasetName in [\"MNIST\"]:\n",
    "#     for m in [1, 10]: # Number of subspaces\n",
    "\n",
    "#         # load\n",
    "#         A = torch.load(f'{datasetDir}/{datasetName}_A.pt') # [392 x 60000]\n",
    "#         B = torch.load(f'{datasetDir}/{datasetName}_B.pt') # [392 x 60000]\n",
    "\n",
    "#         saveCodewordsAndLookUpTable(A, A.T, m, \"AA\")\n",
    "#         saveCodewordsAndLookUpTable(A, B.T, m, \"AB\")\n",
    "#         saveCodewordsAndLookUpTable(B, B.T, m, \"BB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantize backup\n",
    "\n",
    "# chunk_size = 50  # Initial chunk size\n",
    "# C2_quantized = []\n",
    "# D2_quantized = []\n",
    "# for k in range(m):\n",
    "#     codewords_d = codewords_B[k]\n",
    "#     D_subspace = D[k * CD : (k + 1) * CD, :]  # torch.Size([20, 300])\n",
    "\n",
    "#     closest_codeword_indices_list = []  # Store closest codeword indices for each chunk\n",
    "\n",
    "#     for j in range(0, D_subspace.size(1), chunk_size):\n",
    "#         chunk_end = min(j + chunk_size, D_subspace.size(1))\n",
    "#         D_subspace_sub = D_subspace[:, j : chunk_end]\n",
    "        \n",
    "#         distances = torch.norm(codewords_d.unsqueeze(0) - torch.swapaxes(D_subspace_sub.unsqueeze(1), 0, 2), dim=2, p=2)\n",
    "#         closest_codeword_indices_sub = torch.argmin(distances, dim=1)\n",
    "#         closest_codeword_indices_list.append(closest_codeword_indices_sub)\n",
    "\n",
    "#     closest_codeword_indices = torch.cat(closest_codeword_indices_list, dim=0)\n",
    "#     D2_quantized.append(closest_codeword_indices.T)\n",
    "\n",
    "# D2_quantized = torch.stack(D2_quantized, dim=0)  # torch.Size([5, 300])\n",
    "# (D_quantized==D2_quantized).all()\n",
    "\n",
    "# for k in range(m):\n",
    "#     codewords_d = codewords_B[k]\n",
    "#     D_subspace = D[k * CD : (k + 1) * CD, :].T  # torch.Size([20, 300])\n",
    "\n",
    "#     closest_codeword_indices_list = []  # Store closest codeword indices for each chunk\n",
    "\n",
    "#     for j in range(0, D_subspace.size(0), chunk_size):\n",
    "#         chunk_end = min(j + chunk_size, D_subspace.size(0))\n",
    "#         D_subspace_sub = D_subspace[j : chunk_end, :]\n",
    "        \n",
    "#         distances = torch.norm(codewords_d.unsqueeze(0) - D_subspace_sub.unsqueeze(1), dim=2, p=2)\n",
    "#         closest_codeword_indices_sub = torch.argmin(distances, dim=1)\n",
    "#         closest_codeword_indices_list.append(closest_codeword_indices_sub)\n",
    "\n",
    "#     closest_codeword_indices = torch.cat(closest_codeword_indices_list, dim=0)\n",
    "#     D2_quantized.append(closest_codeword_indices)\n",
    "\n",
    "# D2_quantized = torch.stack(D2_quantized, dim=0)  # torch.Size([5, 300])\n",
    "# (D_quantized==D2_quantized).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
