{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have have run the executable of step1SaveMtxToPt.cpp, in you MtxPt/ under build/ dir, you should get\n",
    "\n",
    "```\n",
    "/home/miter/projects/AMMBench/build/benchmark/torchscripts/VQ/MtxPt\n",
    "├── MNIST_A.pt\n",
    "├── MNIST_B.pt\n",
    "├── SIFT10K_A.pt\n",
    "└── SIFT10K_B.pt\n",
    "```\n",
    "\n",
    "This jupuyer is to generate the codeword & lookup table for each pair of matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCodewordAndLookUpTable(A, B, m, ratio_of_num_centroid_over_A_cols=0.1):\n",
    "    \n",
    "    # Sample matrix sizes and PQ parameters\n",
    "    A_rows, A_cols = A.shape\n",
    "    lA = min(int(A_rows // m * ratio_of_num_centroid_over_A_cols), A_rows)  # Number of centroids for each subspace\n",
    "    CA = A_cols // m  # Dimension of each subspace\n",
    "\n",
    "    # Sample matrix sizes and PQ parameters\n",
    "    B_rows, B_cols = B.shape\n",
    "    lB = min(int(B_cols // m * ratio_of_num_centroid_over_A_cols), B_cols)  # Number of centroids for each subspace\n",
    "    CB = B_rows // m  # Dimension of each subspace\n",
    "\n",
    "    # Initialize lists to store subspaces and centroids\n",
    "    subspaces_A = []\n",
    "    codewords_A = []\n",
    "\n",
    "    # Create subspaces and centroids\n",
    "    for i in range(m):\n",
    "        subspace_A = A[:, i * CA : (i + 1) * CA]  # 500*20\n",
    "        subspaces_A.append(subspace_A)\n",
    "\n",
    "        # Apply KMeans on the row vectors within the subspace\n",
    "        kmeans = KMeans(n_clusters=lA, n_init=10)\n",
    "        kmeans.fit(subspace_A)  # 500*20\n",
    "        subspace_centroids_A = torch.tensor(kmeans.cluster_centers_) # 10*20\n",
    "        codewords_A.append(subspace_centroids_A)\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    subspaces_A = torch.stack(subspaces_A, dim=0)\n",
    "    codewords_A = torch.stack(codewords_A, dim=0) # 5*10*20\n",
    "\n",
    "    print(\"Subspaces A shape:\", subspaces_A.shape) # torch.Size([5, 500, 20])\n",
    "    print(\"Codewords A shape:\", codewords_A.shape) # torch.Size([5, 10, 20])\n",
    "\n",
    "\n",
    "    # Initialize lists to store subspaces and centroids\n",
    "    subspaces_B = []\n",
    "    codewords_B = []\n",
    "\n",
    "    # Create subspaces and centroids\n",
    "    for k in range(m):\n",
    "        subspace_B = B[k * CB : (k + 1) * CB, :]  # Extract the subspace along x-axis\n",
    "        subspaces_B.append(subspace_B)\n",
    "\n",
    "        # Apply KMeans on the column vectors within the subspace\n",
    "        kmeans = KMeans(n_clusters=lB, n_init=10)\n",
    "        kmeans.fit(subspace_B.T)  # Transpose to cluster along columns (column vectors)\n",
    "        subspace_centroids_B = torch.tensor(kmeans.cluster_centers_)\n",
    "        codewords_B.append(subspace_centroids_B)\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    subspaces_B = torch.stack(subspaces_B, dim=0)\n",
    "    codewords_B = torch.stack(codewords_B, dim=0)\n",
    "\n",
    "    print(\"Subspaces B shape:\", subspaces_B.shape)  # torch.Size([5, 20, 300])\n",
    "    print(\"Codewords B shape:\", codewords_B.shape)  # torch.Size([5, 6, 20])\n",
    "\n",
    "    # Sample precomputed codewords for A and B (You should replace these with your actual codewords)\n",
    "    lookup_table = torch.zeros((m,lA,lB))\n",
    "    for i in range(m):\n",
    "        for j in range(lA):\n",
    "            for k in range(lB):\n",
    "                lookup_table[i][j][k] = torch.matmul(codewords_A[i][j], codewords_B[i][k]) # for each subspace, get catersian product of A,B codeword\n",
    "\n",
    "    print(\"lookup_table.shape: \", lookup_table.shape)\n",
    "\n",
    "    return lA, lB, codewords_A, codewords_B, lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(C, D, codewords_A, codewords_B, lookup_table):\n",
    "    m = codewords_A.shape[0]\n",
    "\n",
    "    # Sample matrix sizes and PQ parameters\n",
    "    C_rows, C_cols = C.shape\n",
    "    CC = codewords_A.shape[2]  # Dimension of each subspace for matrix C\n",
    "\n",
    "    D_rows, D_cols = D.shape\n",
    "    CD = codewords_B.shape[2]  # Dimension of each subspace for matrix D\n",
    "\n",
    "    # Initialize lists to store quantized indices\n",
    "    C_quantized = []\n",
    "    D_quantized = []\n",
    "\n",
    "    # Find the nearest codeword indices for matrix C\n",
    "    for i in range(m):\n",
    "        codewords_c = codewords_A[i] # torch.Size([10, 20])\n",
    "        C_subspace = C[:, i * CC : (i + 1) * CC] # torch.Size([500, 20])\n",
    "        distances = torch.norm(codewords_c.unsqueeze(0) - C_subspace.unsqueeze(1), dim=2, p=2) # torch.Size([500, 10]) = torch.Size([1, 10, 20]) - torch.Size([500, 1, 20])\n",
    "        closest_codeword_indices = torch.argmin(distances, dim=1) # torch.Size([500])\n",
    "        C_quantized.append(closest_codeword_indices)\n",
    "    C_quantized = torch.stack(C_quantized, dim=1) # torch.Size([500, 5])\n",
    "    # print(\"C quantized shape:\", C_quantized.shape)  # Shape of the quantized indices for C\n",
    "\n",
    "    # Find the nearest codeword indices for matrix D\n",
    "    for k in range(m):\n",
    "        codewords_d = codewords_B[k]\n",
    "        D_subspace = D[k * CD : (k + 1) * CD, :] # torch.Size([20, 300])\n",
    "        distances = torch.norm(codewords_d.unsqueeze(0) - torch.swapaxes(D_subspace.unsqueeze(1), 0, 2), dim=2, p=2) # torch.Size([300, 6]) = torch.Size([1, 6, 20]) - torch.Size([300, 1, 20])\n",
    "        closest_codeword_indices = torch.argmin(distances, dim=1) # torch.Size([300])\n",
    "        D_quantized.append(closest_codeword_indices.T)\n",
    "    D_quantized = torch.stack(D_quantized, dim=0) # torch.Size([5, 300])\n",
    "    # print(\"D quantized shape:\", D_quantized.shape)  # Shape of the quantized indices for D\n",
    "\n",
    "    # Define the batch size for batch processing\n",
    "    batch_size_C = C_rows\n",
    "    batch_size_D = D_cols\n",
    "\n",
    "    # Initialize the matrix products\n",
    "    matrix_products = torch.zeros((C_rows, D_cols))\n",
    "\n",
    "    # Perform matrix multiplication using batch processing\n",
    "    for i in range(0, C_rows, batch_size_C):\n",
    "        for j in range(0, D_cols, batch_size_D):\n",
    "            batch_result = torch.zeros((batch_size_C, batch_size_D))\n",
    "            \n",
    "            for k in range(m):\n",
    "                # Gather quantized indices for the current batch\n",
    "                C_indices = C_quantized[i:i+batch_size_C, k]\n",
    "                D_indices = D_quantized[k, j:j+batch_size_D]\n",
    "                \n",
    "                # Gather relevant entries from the lookup table\n",
    "                batch_lookup = lookup_table[k, C_indices, :][:, D_indices]\n",
    "                \n",
    "                # Accumulate the batch result\n",
    "                batch_result += batch_lookup\n",
    "            \n",
    "            # Assign the batch result to the corresponding position in the matrix products\n",
    "            matrix_products[i:i+batch_size_C, j:j+batch_size_D] = batch_result\n",
    "\n",
    "    E = torch.matmul(C, D)\n",
    "    return torch.norm(matrix_products-E)/torch.norm(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to save codeword and lookup_table to pt\n",
    "class TensorContainer(nn.Module):\n",
    "    def __init__(self, tensor_dict):\n",
    "        super().__init__()\n",
    "        for key,value in tensor_dict.items():\n",
    "            setattr(self, key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasetDir = '/home/miter/projects/AMMBench/build/benchmark/torchscripts/VQ/MtxPt'\n",
    "# saveDir = '/home/miter/projects/AMMBench/build/benchmark/torchscripts/VQ/CodewordLookUpTable'\n",
    "\n",
    "# for datasetName in [\"AST\",\"BUS\",\"DWAVE\",\"ECO\",\"QCD\",\"RDB\",\"UTM\",\"ZENIOS\"]:\n",
    "#     for m in [1, 10]: # Number of subspaces\n",
    "\n",
    "#         # load\n",
    "#         A = torch.load(f'{datasetDir}/{datasetName}_A.pt')\n",
    "#         B = torch.load(f'{datasetDir}/{datasetName}_B.pt')\n",
    "\n",
    "#         # calculate codeword and lookup_table\n",
    "#         lA, lB, codewords_A, codewords_B, lookup_table = getCodewordAndLookUpTable(A, B, m)\n",
    "\n",
    "#         # calculate error\n",
    "#         C=A # actually C,D are testing matrices, and usually different from training matrices A,B. but its ok to make them the same also, cuz we more focus on latency\n",
    "#         D=B\n",
    "#         relativeFroError = quantize(C, D, codewords_A, codewords_B, lookup_table)\n",
    "\n",
    "#         # save codeword and lookup_table\n",
    "#         tensor_dict = {\n",
    "#             # 'A': A,\n",
    "#             # 'B': B,\n",
    "#             'codewordsA': codewords_A,\n",
    "#             'codewordsB': codewords_B,\n",
    "#             'lookUpTable': lookup_table,\n",
    "#             'datasetName': datasetName,\n",
    "#             'm': m,\n",
    "#             'lA': lA,\n",
    "#             'lB': lB,\n",
    "#             'relativeFroError': relativeFroError\n",
    "#         }\n",
    "#         tensors = TensorContainer(tensor_dict)\n",
    "#         tensors = torch.jit.script(tensors)\n",
    "#         tensors.save(f'{saveDir}/{datasetName}_m{m}_lA{lA}_lB{lB}.pth')\n",
    "#         print(datasetName, m, lA, lB, relativeFroError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasetDir = '/home/shuhao/Downloads/AMMBench/build/benchmark/torchscripts/VQ/MtxPt'\n",
    "# saveDir = '/home/shuhao/Downloads/AMMBench/build/benchmark/torchscripts/VQ/CodewordLookUpTable'\n",
    "\n",
    "# for datasetName in [\"SIFT10K\"]:\n",
    "#     for m in [1, 10]: # Number of subspaces\n",
    "\n",
    "#         # load\n",
    "#         A = torch.load(f'{datasetDir}/{datasetName}_A.pt')\n",
    "#         B = torch.load(f'{datasetDir}/{datasetName}_B.pt')\n",
    "\n",
    "#         # calculate codeword and lookup_table\n",
    "#         lA, lB, codewords_A, codewords_B, lookup_table = getCodewordAndLookUpTable(A, B, m)\n",
    "\n",
    "#         # calculate error\n",
    "#         C=A # actually C,D are testing matrices, and usually different from training matrices A,B. but its ok to make them the same also, cuz we more focus on latency\n",
    "#         D=B\n",
    "#         relativeFroError = \"notCalculated\" #quantize(C, D, codewords_A, codewords_B, lookup_table)\n",
    "\n",
    "#         # save codeword and lookup_table\n",
    "#         tensor_dict = {\n",
    "#             # 'A': A,\n",
    "#             # 'B': B,\n",
    "#             'codewordsA': codewords_A,\n",
    "#             'codewordsB': codewords_B,\n",
    "#             'lookUpTable': lookup_table,\n",
    "#             'datasetName': datasetName,\n",
    "#             'm': m,\n",
    "#             'lA': lA,\n",
    "#             'lB': lB,\n",
    "#             'relativeFroError': relativeFroError\n",
    "#         }\n",
    "#         tensors = TensorContainer(tensor_dict)\n",
    "#         tensors = torch.jit.script(tensors)\n",
    "#         tensors.save(f'{saveDir}/{datasetName}_m{m}_lA{lA}_lB{lB}.pth')\n",
    "#         print(datasetName, m, lA, lB, relativeFroError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def saveCodewordsAndLookUpTable(A, B, m, prefix):\n",
    "#     # calculate codeword and lookup_table\n",
    "#     lA, lB, codewords_A, codewords_B, lookup_table = getCodewordAndLookUpTable(A, B, m, 1)\n",
    "#     # calculate error\n",
    "#     C=A\n",
    "#     D=B\n",
    "#     relativeFroError = \"notCalculated\" #quantize(C, D, codewords_A, codewords_B, lookup_table)\n",
    "#     # save codeword and lookup_table\n",
    "#     tensor_dict = {\n",
    "#         # 'A': A,\n",
    "#         # 'B': B,\n",
    "#         'codewordsA': codewords_A,\n",
    "#         'codewordsB': codewords_B,\n",
    "#         'lookUpTable': lookup_table,\n",
    "#         'datasetName': datasetName,\n",
    "#         'm': m,\n",
    "#         'lA': lA,\n",
    "#         'lB': lB,\n",
    "#         'relativeFroError': relativeFroError\n",
    "#     }\n",
    "#     tensors = TensorContainer(tensor_dict)\n",
    "#     tensors = torch.jit.script(tensors)\n",
    "#     tensors.save(f'{saveDir}/{datasetName}_{prefix}_m{m}_lA{lA}_lB{lB}.pth')\n",
    "#     print(prefix, datasetName, m, lA, lB, relativeFroError)\n",
    "    \n",
    "# datasetDir = '/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/build/benchmark/torchscripts/VQ/MtxPt'\n",
    "# saveDir = '/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/CodewordLookUpTable'\n",
    "\n",
    "# for datasetName in [\"MNIST\"]:\n",
    "#     for m in [1, 10]: # Number of subspaces\n",
    "\n",
    "#         # load\n",
    "#         A = torch.load(f'{datasetDir}/{datasetName}_A.pt') # [392 x 60000]\n",
    "#         B = torch.load(f'{datasetDir}/{datasetName}_B.pt') # [392 x 60000]\n",
    "\n",
    "#         saveCodewordsAndLookUpTable(A, A.T, m, \"AA\")\n",
    "#         saveCodewordsAndLookUpTable(A, B.T, m, \"AB\")\n",
    "#         saveCodewordsAndLookUpTable(B, B.T, m, \"BB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subspaces A shape: torch.Size([1, 120, 43907])\n",
      "Codewords A shape: torch.Size([1, 99, 43907])\n",
      "Subspaces B shape: torch.Size([1, 43907, 120])\n",
      "Codewords B shape: torch.Size([1, 99, 43907])\n",
      "lookup_table.shape:  torch.Size([1, 99, 99])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_174216/339523738.py:31: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3277.)\n",
      "  D_quantized.append(closest_codeword_indices.T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA MediaMill 1 99 99 tensor(0.0104, dtype=torch.float64)\n",
      "Subspaces A shape: torch.Size([1, 120, 43907])\n",
      "Codewords A shape: torch.Size([1, 99, 43907])\n",
      "Subspaces B shape: torch.Size([1, 43907, 101])\n",
      "Codewords B shape: torch.Size([1, 83, 43907])\n",
      "lookup_table.shape:  torch.Size([1, 99, 83])\n",
      "AB MediaMill 1 99 83 tensor(0.0078, dtype=torch.float64)\n",
      "Subspaces A shape: torch.Size([1, 101, 43907])\n",
      "Codewords A shape: torch.Size([1, 83, 43907])\n",
      "Subspaces B shape: torch.Size([1, 43907, 101])\n",
      "Codewords B shape: torch.Size([1, 83, 43907])\n",
      "lookup_table.shape:  torch.Size([1, 83, 83])\n",
      "BB MediaMill 1 83 83 tensor(0.0044, dtype=torch.float64)\n",
      "Subspaces A shape: torch.Size([10, 120, 4390])\n",
      "Codewords A shape: torch.Size([10, 9, 4390])\n",
      "Subspaces B shape: torch.Size([10, 4390, 120])\n",
      "Codewords B shape: torch.Size([10, 9, 4390])\n",
      "lookup_table.shape:  torch.Size([10, 9, 9])\n",
      "AA MediaMill 10 9 9 tensor(0.0743, dtype=torch.float64)\n",
      "Subspaces A shape: torch.Size([10, 120, 4390])\n",
      "Codewords A shape: torch.Size([10, 9, 4390])\n",
      "Subspaces B shape: torch.Size([10, 4390, 101])\n",
      "Codewords B shape: torch.Size([10, 8, 4390])\n",
      "lookup_table.shape:  torch.Size([10, 9, 8])\n",
      "AB MediaMill 10 9 8 tensor(0.1692, dtype=torch.float64)\n",
      "Subspaces A shape: torch.Size([10, 101, 4390])\n",
      "Codewords A shape: torch.Size([10, 8, 4390])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb#X11sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m saveCodewordsAndLookUpTable(A, A\u001b[39m.\u001b[39mT, m, \u001b[39m\"\u001b[39m\u001b[39mAA\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m saveCodewordsAndLookUpTable(A, B\u001b[39m.\u001b[39mT, m, \u001b[39m\"\u001b[39m\u001b[39mAB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m saveCodewordsAndLookUpTable(B, B\u001b[39m.\u001b[39;49mT, m, \u001b[39m\"\u001b[39;49m\u001b[39mBB\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msaveCodewordsAndLookUpTable\u001b[39m(A, B, m, prefix):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# calculate codeword and lookup_table\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     lA, lB, codewords_A, codewords_B, lookup_table \u001b[39m=\u001b[39m getCodewordAndLookUpTable(A, B, m, \u001b[39m0.83\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# calculate error\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     C\u001b[39m=\u001b[39mA\n",
      "\u001b[1;32m/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb#X11sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Apply KMeans on the column vectors within the subspace\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb#X11sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m kmeans \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39mlB, n_init\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb#X11sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m kmeans\u001b[39m.\u001b[39;49mfit(subspace_B\u001b[39m.\u001b[39;49mT)  \u001b[39m# Transpose to cluster along columns (column vectors)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m subspace_centroids_B \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(kmeans\u001b[39m.\u001b[39mcluster_centers_)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/step2CalculateCodewordLookUpTable.ipynb#X11sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m codewords_B\u001b[39m.\u001b[39mappend(subspace_centroids_B)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1515\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1511\u001b[0m best_inertia, best_labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_init):\n\u001b[1;32m   1514\u001b[0m     \u001b[39m# Initialize centers\u001b[39;00m\n\u001b[0;32m-> 1515\u001b[0m     centers_init \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_centroids(\n\u001b[1;32m   1516\u001b[0m         X,\n\u001b[1;32m   1517\u001b[0m         x_squared_norms\u001b[39m=\u001b[39;49mx_squared_norms,\n\u001b[1;32m   1518\u001b[0m         init\u001b[39m=\u001b[39;49minit,\n\u001b[1;32m   1519\u001b[0m         random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m   1520\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1521\u001b[0m     )\n\u001b[1;32m   1522\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m   1523\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInitialization complete\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1018\u001b[0m, in \u001b[0;36m_BaseKMeans._init_centroids\u001b[0;34m(self, X, x_squared_norms, init, random_state, init_size, n_centroids, sample_weight)\u001b[0m\n\u001b[1;32m   1015\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight[init_indices]\n\u001b[1;32m   1017\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(init, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m init \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mk-means++\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 1018\u001b[0m     centers, _ \u001b[39m=\u001b[39m _kmeans_plusplus(\n\u001b[1;32m   1019\u001b[0m         X,\n\u001b[1;32m   1020\u001b[0m         n_clusters,\n\u001b[1;32m   1021\u001b[0m         random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m   1022\u001b[0m         x_squared_norms\u001b[39m=\u001b[39;49mx_squared_norms,\n\u001b[1;32m   1023\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1025\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(init, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m init \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1026\u001b[0m     seeds \u001b[39m=\u001b[39m random_state\u001b[39m.\u001b[39mchoice(\n\u001b[1;32m   1027\u001b[0m         n_samples,\n\u001b[1;32m   1028\u001b[0m         size\u001b[39m=\u001b[39mn_clusters,\n\u001b[1;32m   1029\u001b[0m         replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1030\u001b[0m         p\u001b[39m=\u001b[39msample_weight \u001b[39m/\u001b[39m sample_weight\u001b[39m.\u001b[39msum(),\n\u001b[1;32m   1031\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:255\u001b[0m, in \u001b[0;36m_kmeans_plusplus\u001b[0;34m(X, n_clusters, x_squared_norms, sample_weight, random_state, n_local_trials)\u001b[0m\n\u001b[1;32m    252\u001b[0m np\u001b[39m.\u001b[39mclip(candidate_ids, \u001b[39mNone\u001b[39;00m, closest_dist_sq\u001b[39m.\u001b[39msize \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, out\u001b[39m=\u001b[39mcandidate_ids)\n\u001b[1;32m    254\u001b[0m \u001b[39m# Compute distances to center candidates\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m distance_to_candidates \u001b[39m=\u001b[39m _euclidean_distances(\n\u001b[1;32m    256\u001b[0m     X[candidate_ids], X, Y_norm_squared\u001b[39m=\u001b[39;49mx_squared_norms, squared\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    257\u001b[0m )\n\u001b[1;32m    259\u001b[0m \u001b[39m# update closest distances squared and potential for each candidate\u001b[39;00m\n\u001b[1;32m    260\u001b[0m np\u001b[39m.\u001b[39mminimum(closest_dist_sq, distance_to_candidates, out\u001b[39m=\u001b[39mdistance_to_candidates)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:379\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    376\u001b[0m     distances \u001b[39m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[1;32m    377\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[39m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m     distances \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m safe_sparse_dot(X, Y\u001b[39m.\u001b[39;49mT, dense_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    380\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m XX\n\u001b[1;32m    381\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m YY\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/extmath.py:196\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39m b\n\u001b[1;32m    195\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m--> 196\u001b[0m     sparse\u001b[39m.\u001b[39;49missparse(a)\n\u001b[1;32m    197\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[1;32m    198\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[1;32m    199\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m ):\n\u001b[1;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m    202\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_base.py:1461\u001b[0m, in \u001b[0;36missparse\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m sparray\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m \u001b[39m=\u001b[39m _spbase\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m\n\u001b[0;32m-> 1461\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39missparse\u001b[39m(x):\n\u001b[1;32m   1462\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Is `x` of a sparse array type?\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \n\u001b[1;32m   1464\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   1486\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def saveCodewordsAndLookUpTable(A, B, m, prefix):\n",
    "    # calculate codeword and lookup_table\n",
    "    lA, lB, codewords_A, codewords_B, lookup_table = getCodewordAndLookUpTable(A, B, m, 0.83)\n",
    "    # calculate error\n",
    "    C=A\n",
    "    D=B\n",
    "    relativeFroError = quantize(C, D, codewords_A, codewords_B, lookup_table)\n",
    "    # save codeword and lookup_table\n",
    "    tensor_dict = {\n",
    "        'codewordsA': codewords_A,\n",
    "        'codewordsB': codewords_B,\n",
    "        'lookUpTable': lookup_table,\n",
    "        'datasetName': datasetName,\n",
    "        'm': m,\n",
    "        'lA': lA,\n",
    "        'lB': lB,\n",
    "        'relativeFroError': relativeFroError\n",
    "    }\n",
    "    tensors = TensorContainer(tensor_dict)\n",
    "    tensors = torch.jit.script(tensors)\n",
    "    tensors.save(f'{saveDir}/{datasetName}_{prefix}_m{m}_lA{lA}_lB{lB}.pth')\n",
    "    print(prefix, datasetName, m, lA, lB, relativeFroError)\n",
    "    \n",
    "datasetName = 'MediaMill'\n",
    "saveDir = '/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/torchscripts/VQ/CodewordLookUpTable'\n",
    "\n",
    "# Load the saved ScriptModule\n",
    "loaded_module = torch.jit.load('/home/yuhao/Documents/work/SUTD/AMM/codespace/AMMBench/benchmark/datasets/MediaMill/MediaMill.pth')\n",
    "\n",
    "# Access tensors from the loaded module\n",
    "A = loaded_module.A # torch.Size([120, 43907])\n",
    "B = loaded_module.B # torch.Size([101, 43907])\n",
    "\n",
    "for m in [1, 10]: # Number of subspaces\n",
    "    saveCodewordsAndLookUpTable(A, A.T, m, \"AA\")\n",
    "    saveCodewordsAndLookUpTable(A, B.T, m, \"AB\")\n",
    "    saveCodewordsAndLookUpTable(B, B.T, m, \"BB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is for C++ when calculate AMM in batch according to codewords and look-up table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def quantize(C, D, codewords_A, codewords_B, lookup_table):\n",
    "#     m = codewords_A.shape[0]\n",
    "\n",
    "#     # Sample matrix sizes and PQ parameters\n",
    "#     C_rows, C_cols = C.shape\n",
    "#     CC = codewords_A.shape[2]  # Dimension of each subspace for matrix C\n",
    "\n",
    "#     D_rows, D_cols = D.shape\n",
    "#     CD = codewords_B.shape[2]  # Dimension of each subspace for matrix D\n",
    "\n",
    "#     # Initialize lists to store quantized indices\n",
    "#     C_quantized = []\n",
    "#     D_quantized = []\n",
    "\n",
    "#     # Find the nearest codeword indices for matrix C\n",
    "#     for i in range(m):\n",
    "#         codewords_c = codewords_A[i] # torch.Size([10, 20])\n",
    "#         C_subspace = C[:, i * CC : (i + 1) * CC] # torch.Size([500, 20])\n",
    "#         distances = torch.norm(codewords_c.unsqueeze(0) - C_subspace.unsqueeze(1), dim=2, p=2) # torch.Size([500, 10]) = torch.Size([1, 10, 20]) - torch.Size([500, 1, 20])\n",
    "#         closest_codeword_indices = torch.argmin(distances, dim=1) # torch.Size([500])\n",
    "#         C_quantized.append(closest_codeword_indices)\n",
    "#     C_quantized = torch.stack(C_quantized, dim=1) # torch.Size([500, 5])\n",
    "#     # print(\"C quantized shape:\", C_quantized.shape)  # Shape of the quantized indices for C\n",
    "\n",
    "#     # Find the nearest codeword indices for matrix D\n",
    "#     for k in range(m):\n",
    "#         codewords_d = codewords_B[k]\n",
    "#         D_subspace = D[k * CD : (k + 1) * CD, :] # torch.Size([20, 300])\n",
    "#         distances = torch.norm(codewords_d.unsqueeze(0) - torch.swapaxes(D_subspace.unsqueeze(1), 0, 2), dim=2, p=2) # torch.Size([300, 6]) = torch.Size([1, 6, 20]) - torch.Size([300, 1, 20])\n",
    "#         closest_codeword_indices = torch.argmin(distances, dim=1) # torch.Size([300])\n",
    "#         D_quantized.append(closest_codeword_indices.T)\n",
    "#     D_quantized = torch.stack(D_quantized, dim=0) # torch.Size([5, 300])\n",
    "#     # print(\"D quantized shape:\", D_quantized.shape)  # Shape of the quantized indices for D\n",
    "\n",
    "#     # Define the batch size for batch processing\n",
    "#     batch_size_C = C_rows\n",
    "#     batch_size_D = D_cols\n",
    "\n",
    "#     # Initialize the matrix products\n",
    "#     matrix_products = torch.zeros((C_rows, D_cols))\n",
    "\n",
    "#     # Perform matrix multiplication using batch processing\n",
    "#     for i in range(0, C_rows, batch_size_C):\n",
    "#         for j in range(0, D_cols, batch_size_D):\n",
    "#             batch_result = torch.zeros((batch_size_C, batch_size_D))\n",
    "            \n",
    "#             for k in range(m):\n",
    "#                 # Gather quantized indices for the current batch\n",
    "#                 C_indices = C_quantized[i:i+batch_size_C, k]\n",
    "#                 D_indices = D_quantized[k, j:j+batch_size_D]\n",
    "                \n",
    "#                 # Gather relevant entries from the lookup table\n",
    "#                 batch_lookup = lookup_table[k, C_indices, :][:, D_indices]\n",
    "                \n",
    "#                 # Accumulate the batch result\n",
    "#                 batch_result += batch_lookup\n",
    "            \n",
    "#             # Assign the batch result to the corresponding position in the matrix products\n",
    "#             matrix_products[i:i+batch_size_C, j:j+batch_size_D] = batch_result\n",
    "\n",
    "#     E = torch.matmul(C, D)\n",
    "#     return torch.norm(matrix_products-E)/torch.norm(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantize backup\n",
    "\n",
    "# chunk_size = 50  # Initial chunk size\n",
    "# C2_quantized = []\n",
    "# D2_quantized = []\n",
    "# for k in range(m):\n",
    "#     codewords_d = codewords_B[k]\n",
    "#     D_subspace = D[k * CD : (k + 1) * CD, :]  # torch.Size([20, 300])\n",
    "\n",
    "#     closest_codeword_indices_list = []  # Store closest codeword indices for each chunk\n",
    "\n",
    "#     for j in range(0, D_subspace.size(1), chunk_size):\n",
    "#         chunk_end = min(j + chunk_size, D_subspace.size(1))\n",
    "#         D_subspace_sub = D_subspace[:, j : chunk_end]\n",
    "        \n",
    "#         distances = torch.norm(codewords_d.unsqueeze(0) - torch.swapaxes(D_subspace_sub.unsqueeze(1), 0, 2), dim=2, p=2)\n",
    "#         closest_codeword_indices_sub = torch.argmin(distances, dim=1)\n",
    "#         closest_codeword_indices_list.append(closest_codeword_indices_sub)\n",
    "\n",
    "#     closest_codeword_indices = torch.cat(closest_codeword_indices_list, dim=0)\n",
    "#     D2_quantized.append(closest_codeword_indices.T)\n",
    "\n",
    "# D2_quantized = torch.stack(D2_quantized, dim=0)  # torch.Size([5, 300])\n",
    "# (D_quantized==D2_quantized).all()\n",
    "\n",
    "# for k in range(m):\n",
    "#     codewords_d = codewords_B[k]\n",
    "#     D_subspace = D[k * CD : (k + 1) * CD, :].T  # torch.Size([20, 300])\n",
    "\n",
    "#     closest_codeword_indices_list = []  # Store closest codeword indices for each chunk\n",
    "\n",
    "#     for j in range(0, D_subspace.size(0), chunk_size):\n",
    "#         chunk_end = min(j + chunk_size, D_subspace.size(0))\n",
    "#         D_subspace_sub = D_subspace[j : chunk_end, :]\n",
    "        \n",
    "#         distances = torch.norm(codewords_d.unsqueeze(0) - D_subspace_sub.unsqueeze(1), dim=2, p=2)\n",
    "#         closest_codeword_indices_sub = torch.argmin(distances, dim=1)\n",
    "#         closest_codeword_indices_list.append(closest_codeword_indices_sub)\n",
    "\n",
    "#     closest_codeword_indices = torch.cat(closest_codeword_indices_list, dim=0)\n",
    "#     D2_quantized.append(closest_codeword_indices)\n",
    "\n",
    "# D2_quantized = torch.stack(D2_quantized, dim=0)  # torch.Size([5, 300])\n",
    "# (D_quantized==D2_quantized).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
